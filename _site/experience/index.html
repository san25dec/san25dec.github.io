<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      Experience &middot; Santhosh Kumar
    
  </title>
  
  <!-- MathJax hack -->
  <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  <script type="text/javascript" src=//js/jquery-1.11.3.min.js></script>
  <script type="text/javascript" src=//js/jq_mathjax_parse.js></script>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-144-precomposed.png">
                                 <link rel="shortcut icon" href="/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">
</head>


  <body>

    <div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/">
			<font size="6"> Santhosh Kumar </font>
        </a>
      </h1>
	  <h2>
          <center><img src=https://raw.githubusercontent.com/san25dec/san25dec.github.io/master/_images/SitePic.jpg style="width:200px;height:200px;"></center>
	  </h2>	
    </div>

    <center>
    <nav class="sidebar-nav">

      
    
      
      
        
          
          

        
      
        
          
            <a class="sidebar-nav-item" href="/biography">Biography</a>
          
          

        
      
        
      
        
          
            <a class="sidebar-nav-item active" href="/experience/">Experience</a>
          
          

        
      
        
          
          

        
      
        
          
            <a class="sidebar-nav-item" href="/projects/">Projects</a>
          
          

        
      
        
          
          
            <a class="sidebar-nav-item" href="/publications/">Publications</a>
          

        
      
        
      
          
      <a class="sidebar-nav-item" href="https://github.com/san25dec/san25dec.github.io/blob/master/_files/SanthoshKumarFull.pdf" >Resume</a>
    </nav>


	<a href="mailto:santhoshkumar.25dec@gmail.com">
	  <i class="fa fa-envelope"></i>
	</a>

	<a href="https://github.com/san25dec">
	  <i class="fa fa-github"></i>
	</a>

	<a href="https://linkedin.com/in/santhosh-kumar-ramakrishnan-548b1150">
	  <i class="fa fa-linkedin"></i>
	</a>

	<a href="https://www.facebook.com/obisankenobi">
      <i class="fa fa-facebook"></i>
    </a>

    </center> 
    <p>&copy; 2017. All rights reserved.</p>
  </div>
</div>


    <div class="content container">
      <div class="page">
  <h1 class="page-title">Experience</h1>
  <h2 id="summer-internship-2016">Summer Internship 2016</h2>
<p><em>SURGE, IIT Kanpur</em></p>

<p>I worked on Visual Question Answering under the guidance of <a href="http://www.grvsharma.com/research.html">Dr. Gaurav Sharma</a>.
Current state of the art methods use CNNs trained on the ImageNet task (VGGNet, GoogleNet,
 etc). These are independent of the text representation used. An image representation that is aligned with the text representation may improve the VQA performance of existing systems. 
The VQA baseline we used was the <a href="https://github.com/VT-vision-lab/VQA_LSTM_CNN"><em>deeper LSTM + Normalized CNN</em></a>  model from the original VQA dataset paper.
We used <a href="https://github.com/ryankiros/skip-thoughts"><em>SkipThought vectors</em></a> based sentence representation, and aligned the image 
representation with it. Two methods of alignment were explored:</p>

<ul>
  <li>Supervised: Learnt a linear projection using triplet hinge loss and backpropagation</li>
  <li>Unsupervised: Learnt a linear projection using Canonical Correlation Analysis</li>
</ul>

<p>We found that the aligned features were complementary to the original features, and a 
late fusion model obtained <strong>1.5%</strong> improvement over the baseline model.</p>

<h2 id="winter-internship-2014">Winter Internship 2014</h2>
<p><em>HyperVerge Inc.</em></p>

<p>I worked on developing modules for generating object proposals in images. I explored the prototypes (implemented a few) of state of the art models such as Selective Search, Multi-scale Combinatorial Grouping, Objectness, etc.
By evaluating their effectiveness on our specific scenarios, I selected the best model and
implemented it in C++ for testing on real time applications.</p>

<h2 id="summer-internship-2014">Summer Internship 2014</h2>
<p><em>HyperVerge Inc.</em></p>

<p>Our team developed video surveillance modules for performing tasks such as background
subtraction and object tracking. In background subtraction, we implemented several models 
and evaluated them on the existing datasets. We further ported the best performing model on
CUDA, achieving the necessary speed for real-time applications. In object tracking, we
implemented a few existing models and evaluated them on datasets such as VOT2013, PETS2009, etc.</p>

</div>

    </div>

  </body>
</html>
